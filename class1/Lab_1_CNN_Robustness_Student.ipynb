{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6429551",
   "metadata": {},
   "source": [
    "# Lab 1: CNN Robustness Report - Student Notebook\n",
    "\n",
    "## Objective\n",
    "Build a comprehensive CNN robustness report by:\n",
    "1. Training a baseline CNN model\n",
    "2. Detecting overfitting from training curves\n",
    "3. Applying 2 regularization techniques and comparing\n",
    "4. Running adversarial attacks (FGSM)\n",
    "5. Generating a final robustness report\n",
    "\n",
    "## Deliverables\n",
    "Your final report must include:\n",
    "- ‚úÖ Clean accuracy (baseline model)\n",
    "- ‚úÖ Noisy accuracy (Gaussian noise perturbation)\n",
    "- ‚úÖ Adversarial accuracy (FGSM attack)\n",
    "- ‚úÖ Model size (MB)\n",
    "- ‚úÖ Inference time (ms per image)\n",
    "- ‚úÖ Observations (overfitting analysis, regularization effectiveness, robustness assessment)\n",
    "\n",
    "## Instructions\n",
    "- **üî¥ RED CODE**: Code you need to complete (fill in the blanks)\n",
    "- **üü¢ GREEN CODE**: Complete code already provided\n",
    "- **üìù COMMENTS**: Explain what each section does\n",
    "- **üí° HINTS**: Refer to Part 1, 2, 3 notebooks from class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb56c0d",
   "metadata": {},
   "source": [
    "## Section 1: Setup & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656a6b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üü¢ GREEN CODE - Complete (Run this as-is)\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.models import resnet18\n",
    "from tqdm import tqdm\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "print(\"‚úÖ Libraries imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9fc42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üü¢ GREEN CODE - Device and paths\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "DATASET_PATH = r\"C:\\Users\\Lucifer\\python_workspace\\BITS\\AI_Quality_Engineering\\dataset\"\n",
    "TRAIN_PATH = os.path.join(DATASET_PATH, \"train\")\n",
    "VAL_PATH = os.path.join(DATASET_PATH, \"val\")\n",
    "TEST_PATH = os.path.join(DATASET_PATH, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8b1c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üü¢ GREEN CODE - Data transformations and loading\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = ImageFolder(TRAIN_PATH, transform=transform)\n",
    "val_dataset = ImageFolder(VAL_PATH, transform=transform)\n",
    "test_dataset = ImageFolder(TEST_PATH, transform=transform)\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(f\"Classes: {class_names}\")\n",
    "print(f\"Train: {len(train_dataset)} | Val: {len(val_dataset)} | Test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570ec365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî¥ RED CODE - TODO: Create data loaders\n",
    "# Create train_loader, val_loader, test_loader with batch_size=64\n",
    "# Use shuffle=True for train, shuffle=False for val/test\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "train_loader = DataLoader(  # TODO: Complete this line\n",
    "    \n",
    ")\n",
    "val_loader = DataLoader(  # TODO: Complete this line\n",
    "    \n",
    ")\n",
    "test_loader = DataLoader(  # TODO: Complete this line\n",
    "    \n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Data loaders created with batch size {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821bc774",
   "metadata": {},
   "source": [
    "## Section 2: Define Models with Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5105e2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üü¢ GREEN CODE - Baseline model (no regularization)\n",
    "class BaselineModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.resnet = resnet18(pretrained=False)\n",
    "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "print(\"‚úÖ BaselineModel defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0a5aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî¥ RED CODE - TODO: Create L2 Regularized Model\n",
    "# Add L2 regularization using weight_decay in optimizer\n",
    "# This model should be identical to BaselineModel\n",
    "# The difference is in how we create the optimizer (will add weight_decay)\n",
    "\n",
    "class L2RegularizedModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        # TODO: Create ResNet-18 model\n",
    "        # Hint: Same as BaselineModel\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # TODO: Implement forward pass\n",
    "        pass\n",
    "\n",
    "print(\"‚úÖ L2RegularizedModel defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dc9924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî¥ RED CODE - TODO: Create Dropout Model\n",
    "# Add Dropout layer before final classification\n",
    "\n",
    "class DropoutModel(nn.Module):\n",
    "    def __init__(self, num_classes, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.resnet = resnet18(pretrained=False)\n",
    "        # TODO: Replace final layer with sequential containing Dropout + Linear\n",
    "        # Use nn.Sequential(nn.Dropout(dropout_rate), nn.Linear(...))\n",
    "        self.resnet.fc = ___  # TODO: Complete this\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # TODO: Implement forward pass\n",
    "        pass\n",
    "\n",
    "print(\"‚úÖ DropoutModel defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a871b133",
   "metadata": {},
   "source": [
    "## Section 3: Training & Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7624166e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üü¢ GREEN CODE - Training function (complete)\n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    avg_loss = running_loss / len(loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "print(\"‚úÖ train_epoch() defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac9ce11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî¥ RED CODE - TODO: Complete evaluation function\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc=\"Evaluating\", leave=False):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            # TODO: Forward pass\n",
    "            outputs = ___\n",
    "            # TODO: Calculate loss\n",
    "            loss = ___\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    avg_loss = running_loss / len(loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "print(\"‚úÖ evaluate() defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa10345",
   "metadata": {},
   "source": [
    "## Section 4: Train All Three Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f19d2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî¥ RED CODE - TODO: Train Baseline Model\n",
    "# Create model, optimizer, criterion and train for 30 epochs\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training BASELINE Model (No Regularization)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "baseline_model = BaselineModel(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_baseline = optim.Adam(baseline_model.parameters(), lr=0.001)  # TODO: Add weight_decay=0 (or no weight decay)\n",
    "\n",
    "baseline_history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "NUM_EPOCHS = 30\n",
    "\n",
    "# TODO: Complete the training loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss, train_acc = train_epoch(baseline_model, train_loader, criterion, optimizer_baseline, device)\n",
    "    val_loss, val_acc = evaluate(baseline_model, val_loader, criterion, device)\n",
    "    \n",
    "    baseline_history['train_loss'].append(train_loss)\n",
    "    baseline_history['train_acc'].append(train_acc)\n",
    "    baseline_history['val_loss'].append(val_loss)\n",
    "    baseline_history['val_acc'].append(val_acc)\n",
    "    \n",
    "    # TODO: Print epoch results (Epoch [X/30] Train: XXX% Val: XXX%)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] Train Acc: {train_acc:.2f}% | Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "print(\"‚úÖ Baseline model trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb7415c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî¥ RED CODE - TODO: Train L2 Regularized Model\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training L2 REGULARIZED Model (Weight Decay = 0.001)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "l2_model = L2RegularizedModel(num_classes).to(device)\n",
    "# TODO: Create optimizer with weight_decay=0.001\n",
    "optimizer_l2 = optim.Adam(l2_model.parameters(), lr=0.001, weight_decay=___)  # TODO: What weight_decay value?\n",
    "\n",
    "l2_history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "# TODO: Complete the training loop (similar to baseline)\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # TODO: Train and evaluate\n",
    "    # TODO: Update history\n",
    "    # TODO: Print every 10 epochs\n",
    "    pass\n",
    "\n",
    "print(\"‚úÖ L2 Regularized model trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8fe829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî¥ RED CODE - TODO: Train Dropout Model\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training DROPOUT Model (Dropout Rate = 0.5)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "dropout_model = DropoutModel(num_classes, dropout_rate=0.5).to(device)\n",
    "optimizer_dropout = optim.Adam(dropout_model.parameters(), lr=0.001)\n",
    "\n",
    "dropout_history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "# TODO: Complete the training loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # TODO: Implement (same pattern as above)\n",
    "    pass\n",
    "\n",
    "print(\"‚úÖ Dropout model trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7ca999",
   "metadata": {},
   "source": [
    "## Section 5: Detect Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc05d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî¥ RED CODE - TODO: Plot training curves and analyze overfitting\n",
    "# Create a figure with 3 subplots (one for each model)\n",
    "# Each subplot should show train and val accuracy curves\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "fig.suptitle('Overfitting Analysis: Baseline vs L2 vs Dropout', fontsize=16, fontweight='bold')\n",
    "\n",
    "models_data = [\n",
    "    ('Baseline', baseline_history, axes[0]),\n",
    "    ('L2 Regularized', l2_history, axes[1]),\n",
    "    ('Dropout', dropout_history, axes[2])\n",
    "]\n",
    "\n",
    "# TODO: Complete the plotting loop\n",
    "for model_name, history, ax in models_data:\n",
    "    # TODO: Plot train and val accuracy\n",
    "    # TODO: Set labels, title, legend\n",
    "    # TODO: Add grid\n",
    "    pass\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('overfitting_comparison.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Overfit curves plotted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4abb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî¥ RED CODE - TODO: Calculate overfitting metrics\n",
    "# For each model, calculate the gap between final train and val accuracy\n",
    "\n",
    "overfitting_analysis = {}\n",
    "\n",
    "# Baseline\n",
    "baseline_gap = baseline_history['train_acc'][-1] - baseline_history['val_acc'][-1]\n",
    "overfitting_analysis['Baseline'] = baseline_gap\n",
    "\n",
    "# L2 Regularized\n",
    "# TODO: Calculate L2 gap\n",
    "l2_gap = ___\n",
    "overfitting_analysis['L2 Regularized'] = l2_gap\n",
    "\n",
    "# Dropout\n",
    "# TODO: Calculate Dropout gap\n",
    "dropout_gap = ___\n",
    "overfitting_analysis['Dropout'] = dropout_gap\n",
    "\n",
    "print(\"\\nüìä OVERFITTING ANALYSIS (Train-Val Gap):\")\n",
    "for model_name, gap in overfitting_analysis.items():\n",
    "    print(f\"{model_name:20s}: {gap:6.2f}% gap\", end=\"\")\n",
    "    if gap > 10:\n",
    "        print(\" ‚ö†Ô∏è  HIGH OVERFITTING\")\n",
    "    elif gap > 5:\n",
    "        print(\" ‚ö†Ô∏è  MODERATE OVERFITTING\")\n",
    "    else:\n",
    "        print(\" ‚úÖ GOOD GENERALIZATION\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7606549",
   "metadata": {},
   "source": [
    "## Section 6: Model Complexity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7365a547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üü¢ GREEN CODE - Helper functions\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def get_model_size_mb(model):\n",
    "    torch.save(model.state_dict(), \"temp_model.pth\")\n",
    "    size_mb = os.path.getsize(\"temp_model.pth\") / (1024 * 1024)\n",
    "    os.remove(\"temp_model.pth\")\n",
    "    return size_mb\n",
    "\n",
    "print(\"‚úÖ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ba2987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî¥ RED CODE - TODO: Calculate model sizes and parameters\n",
    "model_complexity = {}\n",
    "\n",
    "# TODO: For each model, calculate parameters and size\n",
    "for model_name, model in [('Baseline', baseline_model), ('L2 Regularized', l2_model), ('Dropout', dropout_model)]:\n",
    "    params = count_parameters(model)\n",
    "    size = get_model_size_mb(model)\n",
    "    model_complexity[model_name] = {'params': params, 'size': size}\n",
    "    print(f\"{model_name}: {params:,} parameters | {size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15bd2f1",
   "metadata": {},
   "source": [
    "## Section 7: Robustness Testing - Adversarial Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3532cd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî¥ RED CODE - TODO: Implement Gaussian Noise Perturbation\n",
    "def add_gaussian_noise(images, noise_std=0.1):\n",
    "    \"\"\"\n",
    "    Add Gaussian noise to images.\n",
    "    \n",
    "    Args:\n",
    "        images: Tensor of shape (B, C, H, W)\n",
    "        noise_std: Standard deviation of Gaussian noise\n",
    "    \n",
    "    Returns:\n",
    "        Noisy images (clipped to valid range [-1, 1])\n",
    "    \"\"\"\n",
    "    # TODO: Create random noise with torch.randn_like\n",
    "    # TODO: Add noise to images\n",
    "    # TODO: Clip to [-1, 1]\n",
    "    noise = ___\n",
    "    noisy_images = ___\n",
    "    return torch.clamp(noisy_images, -1, 1)\n",
    "\n",
    "print(\"‚úÖ Gaussian noise function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8243612c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî¥ RED CODE - TODO: Implement FGSM Attack\n",
    "def fgsm_attack(model, images, labels, device, epsilon=0.05):\n",
    "    \"\"\"\n",
    "    Fast Gradient Sign Method (FGSM) Attack.\n",
    "    \n",
    "    Perturb images in the direction of the gradient to fool the model.\n",
    "    \n",
    "    Args:\n",
    "        model: Neural network\n",
    "        images: Input images\n",
    "        labels: True labels\n",
    "        device: Device to run on\n",
    "        epsilon: Attack strength\n",
    "    \n",
    "    Returns:\n",
    "        Adversarial images\n",
    "    \"\"\"\n",
    "    # TODO: Enable gradient tracking for images\n",
    "    images.requires_grad = ___\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(images)\n",
    "    loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "    \n",
    "    # TODO: Compute gradients\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    # TODO: Get gradient sign and create adversarial examples\n",
    "    data_grad = images.grad.data\n",
    "    sign_data_grad = ___\n",
    "    \n",
    "    # TODO: Create perturbed images\n",
    "    perturbed_images = ___\n",
    "    \n",
    "    # Clip to valid range\n",
    "    return torch.clamp(perturbed_images, -1, 1).detach()\n",
    "\n",
    "print(\"‚úÖ FGSM attack function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6639b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî¥ RED CODE - TODO: Evaluate robustness on noisy images\n",
    "def evaluate_on_noisy(model, loader, device, noise_std=0.1):\n",
    "    \"\"\"Evaluate model on Gaussian noise-perturbed images\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc=f\"Testing noise (œÉ={noise_std})\", leave=False):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            # TODO: Add Gaussian noise\n",
    "            noisy_images = ___\n",
    "            # TODO: Get predictions\n",
    "            outputs = ___\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            # TODO: Update accuracy\n",
    "            total += ___\n",
    "            correct += ___\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "print(\"‚úÖ Noisy evaluation function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0566d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî¥ RED CODE - TODO: Evaluate robustness against FGSM attacks\n",
    "def evaluate_on_adversarial(model, loader, device, epsilon=0.05):\n",
    "    \"\"\"Evaluate model on FGSM adversarial examples\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in tqdm(loader, desc=f\"Testing FGSM (Œµ={epsilon})\", leave=False):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # TODO: Generate adversarial examples\n",
    "        adv_images = ___\n",
    "        # TODO: Evaluate on adversarial images\n",
    "        # TODO: Update accuracy\n",
    "        pass\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "print(\"‚úÖ Adversarial evaluation function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa72abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî¥ RED CODE - TODO: Test all models on clean, noisy, and adversarial data\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ROBUSTNESS EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "robustness_results = {}\n",
    "\n",
    "for model_name, model in [('Baseline', baseline_model), ('L2 Regularized', l2_model), ('Dropout', dropout_model)]:\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    \n",
    "    # Clean accuracy\n",
    "    clean_loss, clean_acc = evaluate(model, test_loader, criterion, device)\n",
    "    # TODO: Get noisy accuracy\n",
    "    noisy_acc = ___\n",
    "    # TODO: Get adversarial accuracy\n",
    "    adv_acc = ___\n",
    "    \n",
    "    robustness_results[model_name] = {\n",
    "        'clean': clean_acc,\n",
    "        'noisy': noisy_acc,\n",
    "        'adversarial': adv_acc\n",
    "    }\n",
    "    \n",
    "    print(f\"  Clean Accuracy:       {clean_acc:.2f}%\")\n",
    "    print(f\"  Noisy Accuracy (œÉ=0.1): {noisy_acc:.2f}%\")\n",
    "    print(f\"  Adversarial Accuracy (Œµ=0.05): {adv_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e531486",
   "metadata": {},
   "source": [
    "## Section 8: Generate Final Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1123d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî¥ RED CODE - TODO: Create comprehensive robustness report\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéØ CNN ROBUSTNESS REPORT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìä ACCURACY METRICS:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Model':<25} {'Clean':<15} {'Noisy':<15} {'Adversarial':<15}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# TODO: Print results for each model\n",
    "for model_name in ['Baseline', 'L2 Regularized', 'Dropout']:\n",
    "    # TODO: Get results and print in table format\n",
    "    pass\n",
    "\n",
    "print(\"\\n‚è±Ô∏è  INFERENCE TIME & MODEL SIZE:\")\n",
    "print(\"-\" * 80)\n",
    "# TODO: Print inference time and model size for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69bdc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî¥ RED CODE - TODO: Inference time analysis\n",
    "print(\"\\nüìè MODEL COMPLEXITY:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Model':<25} {'Parameters':<20} {'Size (MB)':<15}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# TODO: Print parameters and size for each model\n",
    "for model_name in ['Baseline', 'L2 Regularized', 'Dropout']:\n",
    "    params = model_complexity[model_name]['params']\n",
    "    size = model_complexity[model_name]['size']\n",
    "    # TODO: Print in table format\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c889bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî¥ RED CODE - TODO: Write your observations\n",
    "print(\"\\nüí° OBSERVATIONS & ANALYSIS:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "observations = \"\"\"\n",
    "Please answer the following questions:\n",
    "\n",
    "1. OVERFITTING ANALYSIS:\n",
    "   - Which model shows the least overfitting? Why?\n",
    "   - TODO: Write your observation here\n",
    "   \n",
    "2. REGULARIZATION EFFECTIVENESS:\n",
    "   - How effective is L2 regularization compared to Dropout?\n",
    "   - TODO: Write your observation here\n",
    "   \n",
    "3. ROBUSTNESS ASSESSMENT:\n",
    "   - Which model is most robust to adversarial attacks?\n",
    "   - What's your hypothesis for why?\n",
    "   - TODO: Write your observation here\n",
    "   \n",
    "4. ACCURACY-COMPLEXITY TRADEOFF:\n",
    "   - Is there a correlation between model size and accuracy?\n",
    "   - TODO: Write your observation here\n",
    "   \n",
    "5. RECOMMENDATIONS:\n",
    "   - Which model would you deploy in production and why?\n",
    "   - TODO: Write your recommendation here\n",
    "\"\"\"\n",
    "\n",
    "print(observations)\n",
    "\n",
    "# TODO: Write your answers below\n",
    "YOUR_OBSERVATIONS = \"\"\"\n",
    "\"\"\"\n",
    "\n",
    "print(YOUR_OBSERVATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68d7eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî¥ RED CODE - TODO: Create final summary visualization\n",
    "# Create a bar chart comparing clean, noisy, and adversarial accuracy for all 3 models\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# TODO: Prepare data for plotting\n",
    "# Hint: Use model names as x-axis, and plot 3 bars per model\n",
    "\n",
    "# TODO: Create grouped bar chart\n",
    "# Note: You'll need to offset the bars for each accuracy type\n",
    "\n",
    "ax.set_xlabel('Model', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Accuracy (%)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Robustness Comparison: Clean vs Noisy vs Adversarial', fontsize=14, fontweight='bold')\n",
    "ax.legend(['Clean', 'Noisy', 'Adversarial'], fontsize=11)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('robustness_summary.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Summary visualization created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6567f6",
   "metadata": {},
   "source": [
    "## Submission Checklist\n",
    "\n",
    "Before submitting, ensure your report includes:\n",
    "\n",
    "- [ ] **Clean Accuracy**: Baseline model test accuracy\n",
    "- [ ] **Noisy Accuracy**: Accuracy with Gaussian noise (œÉ=0.1)\n",
    "- [ ] **Adversarial Accuracy**: Accuracy with FGSM attack (Œµ=0.05)\n",
    "- [ ] **Model Size**: Size in MB for all 3 models\n",
    "- [ ] **Inference Time**: Per-image inference time\n",
    "- [ ] **Overfitting Analysis**: Explanation of train-val gap for each model\n",
    "- [ ] **Regularization Comparison**: Which technique worked better?\n",
    "- [ ] **Robustness Assessment**: Which model is most robust and why?\n",
    "- [ ] **Visualizations**: Training curves and robustness comparison chart\n",
    "- [ ] **Observations**: Detailed answers to all 5 questions above\n",
    "\n",
    "## Questions & Tips\n",
    "\n",
    "- If stuck, refer to Part 1, 2, and 3 notebooks from class\n",
    "- Look for `# TODO:` comments to find missing code\n",
    "- Use the solution notebook only as a last resort!\n",
    "- Good luck! üöÄ"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
