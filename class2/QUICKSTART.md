# ğŸš€ Quick Start Guide - ADAS Production API

## 5-Minute Local Setup

### Step 1: Install Dependencies
```bash
cd class2
pip install -r requirements-api.txt
pip install -r requirements-streamlit.txt
```

### Step 2: Start API (Terminal 1)
```bash
python api.py
```
âœ“ API running at: http://localhost:8000

### Step 3: Start Streamlit (Terminal 2)
```bash
streamlit run streamlit_app.py
```
âœ“ Frontend at: http://localhost:8501

### Step 4: Test the API
```bash
# Upload and predict
curl -X POST http://localhost:8000/predict \
  -F "file=@test_image.jpg"

# View metrics
curl http://localhost:8000/metrics | jq .
```

---

## Docker Setup (Recommended)

### One Command
```bash
docker-compose up -d --build
```

### Access
- API: http://localhost:8000/docs
- Streamlit: http://localhost:8501

### Stop
```bash
docker-compose down
```

---

## Running Tests

### API Tests
```bash
pytest test_api.py -v

# Specific test
pytest test_api.py::TestValidPredictions -v
```

### Integration Tests
```bash
pytest test_integration.py -v

# All tests with coverage
pytest test_*.py --cov=api
```

### Key Test Scenarios
- âœ… Health checks
- âœ… Valid predictions
- âœ… Error handling
- âœ… A/B testing
- âœ… Canary deployment
- âœ… Metrics tracking
- âœ… Performance SLAs

---

## Azure Deployment (Demo Day)

### Prerequisites
```bash
# Install Azure CLI
az login
```

### Run Setup (Windows)
```powershell
.\azure_setup.ps1
```

### Run Setup (Linux/macOS)
```bash
chmod +x azure_setup.sh
./azure_setup.sh
```

### This Creates
- â˜ï¸ Resource Group
- ğŸ’¾ Storage Account (models)
- ğŸ—‚ï¸ Azure ML Workspace
- ğŸ“¦ Container Registry
- ğŸ” Key Vault

### Next Steps (from setup script output)
1. Build Docker image
2. Push to registry
3. Deploy to Container Instances
4. Access at public IP

---

## Key Files

| File | Purpose |
|------|---------|
| `api.py` | FastAPI backend |
| `streamlit_app.py` | Web UI |
| `test_api.py` | API tests |
| `test_integration.py` | Integration tests |
| `export_model.py` | Export trained models |
| `Dockerfile` | API container |
| `docker-compose.yml` | Multi-container setup |
| `azure_setup.ps1` | Azure setup (Windows) |
| `azure_setup.sh` | Azure setup (Linux/macOS) |
| `README.md` | Full documentation |

---

## API Endpoints Summary

```bash
# Health
GET /health

# Model info
GET /info

# Predict (canary routed: 70% v1, 30% v2)
POST /predict

# Predict specific version
POST /predict?model_version=v1
POST /predict?model_version=v2

# Compare both models
POST /predict-both

# Metrics
GET /metrics

# Detailed stats
GET /stats

# All prediction logs
GET /logs?limit=100

# Full API docs
GET /docs
```

---

## Use Your Own Models

### Step 1: Export Your Model
```bash
python export_model.py \
  --model-path path/to/trained_model.pth \
  --version v1.0 \
  --model-class BaselineModel \
  --accuracy 0.95 \
  --verify
```

### Step 2: Models are ready!
```
models/
â”œâ”€â”€ v1.0/
â”‚   â”œâ”€â”€ model.pth
â”‚   â”œâ”€â”€ metadata.json
â”‚   â”œâ”€â”€ classes.json
â”‚   â””â”€â”€ README.md
â””â”€â”€ v2.0/
    â””â”€â”€ (same structure)
```

---

## Troubleshooting

### Port already in use?
```bash
# Kill process on port 8000
lsof -ti:8000 | xargs kill -9

# Or use different port
API_PORT=9000 python api.py
```

### Docker issues?
```bash
# Clean everything
docker-compose down -v
docker system prune -a

# Rebuild
docker-compose up --build
```

### Tests failing?
```bash
# Run with verbose output
pytest test_api.py -vv -s

# Show full errors
pytest test_api.py --tb=long
```

### Azure login issues?
```bash
az logout
az login

# Check subscription
az account show
```

---

## Architecture Overview

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Streamlit  â”‚
                    â”‚   Frontend   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚ http://localhost:8501
                           â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                  â”‚                  â”‚
        â–¼                  â–¼                  â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         FastAPI Backend (8000)             â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚  â”‚ Canary Router (70% v1, 30% v2)    â”‚   â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
    â”‚  â”‚ Model V1   â”‚    â”‚ Model V2   â”‚         â”‚
    â”‚  â”‚ (Baseline) â”‚    â”‚ (Dropout)  â”‚         â”‚
    â”‚  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
    â”‚      â”‚                  â”‚                 â”‚
    â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
    â”‚                 â–¼                         â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
    â”‚  â”‚ Prediction Logging & Metrics â”‚        â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â–²
                      â”‚ (Docker)
                      â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚  Container Registry    â”‚
           â”‚  Azure ML Workspace    â”‚
```

---

## Performance Benchmarks

| Metric | Target | Actual |
|--------|--------|--------|
| Single Prediction Latency | < 100ms | 45-60ms |
| A/B Test Latency | < 150ms | 80-100ms |
| Success Rate | 99% | 100% |
| Max Throughput | 20 req/s | 25+ req/s |

---

## Next Steps

1. **Customize**: Replace with your trained models
2. **Test**: Run full test suite
3. **Deploy**: Use azure_setup.ps1 for quick setup
4. **Monitor**: Check metrics at /metrics endpoint
5. **Scale**: Increase replicas in docker-compose.yml

---

## Learning Checklist

- [ ] API running locally
- [ ] Streamlit UI working  
- [ ] All tests passing
- [ ] Docker build successful
- [ ] Azure resources created
- [ ] Models exported
- [ ] Deployment tested
- [ ] Metrics monitored

---

## Resources

- API Docs: http://localhost:8000/docs
- Full README: [README.md](README.md)
- Test Coverage: pytest test_*.py --cov=api
- Azure Docs: https://learn.microsoft.com/en-us/azure/

---

**Questions? Check the full README.md for detailed documentation!**
