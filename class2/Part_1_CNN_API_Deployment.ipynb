{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1af2fbd7",
   "metadata": {},
   "source": [
    "# Class 2 - Part 1: Deploy CNN as API\n",
    "\n",
    "## Objective\n",
    "In this session, you will:\n",
    "1. Wrap the trained CNN model as a REST API using FastAPI\n",
    "2. Create a `/predict` endpoint that accepts images and returns predictions\n",
    "3. Implement input validation and error handling\n",
    "4. Test the API using Python requests\n",
    "5. Handle edge cases (wrong shape, corrupt images)\n",
    "\n",
    "## Key Concepts\n",
    "- **API Design**: How ML models transition from notebooks to production\n",
    "- **Input Validation**: Ensuring only valid data reaches the model\n",
    "- **Error Handling**: Graceful failure and meaningful error messages\n",
    "- **Model Versioning**: Tracking which model version is serving predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e217f218",
   "metadata": {},
   "source": [
    "## Why APIs?\n",
    "\n",
    "Models in production aren't run in notebooks. They need to be:\n",
    "- **Accessible**: Other applications need to use them\n",
    "- **Scalable**: Handle many concurrent requests\n",
    "- **Reliable**: Never crash the entire system\n",
    "- **Monitored**: Track performance and usage\n",
    "- **Versioned**: Support multiple model versions\n",
    "\n",
    "**REST API** is the standard way to expose ML models to the world."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93e9631",
   "metadata": {},
   "source": [
    "## Step 1: Setup & Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9820b4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries imported\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import json\n",
    "import base64\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "# FastAPI and testing\n",
    "from fastapi import FastAPI, File, UploadFile, HTTPException\n",
    "from fastapi.responses import JSONResponse\n",
    "import uvicorn\n",
    "import requests\n",
    "from pydantic import BaseModel\n",
    "\n",
    "print(\"âœ… Libraries imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "857c953b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "âœ… Classes: ['animal', 'name_board', 'other_vehicle', 'pedestrian', 'pothole', 'road_sign', 'speed_breaker']\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Class names from training\n",
    "class_names = ['animal', 'name_board', 'other_vehicle', 'pedestrian', 'pothole', 'road_sign', 'speed_breaker']\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(f\"âœ… Classes: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "466678fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lucifer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Lucifer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model created (using random weights for demo)\n",
      "   Note: In production, you would load pre-trained weights\n"
     ]
    }
   ],
   "source": [
    "# Create a simple CNN model (same as in Class 1)\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.resnet = resnet18(pretrained=False)\n",
    "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "# Create and move to device\n",
    "model = CNNModel(num_classes).to(device)\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "print(\"âœ… Model created (using random weights for demo)\")\n",
    "print(\"   Note: In production, you would load pre-trained weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47343992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Image transformation pipeline ready\n"
     ]
    }
   ],
   "source": [
    "# Data transformation (same as training)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\"âœ… Image transformation pipeline ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be7ac3d",
   "metadata": {},
   "source": [
    "## Step 2: Create FastAPI Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70e78983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… FastAPI application created\n"
     ]
    }
   ],
   "source": [
    "# Define API response model using Pydantic\n",
    "class PredictionResponse(BaseModel):\n",
    "    \"\"\"Response schema for model predictions\"\"\"\n",
    "    prediction: str  # Class name\n",
    "    confidence: float  # Probability\n",
    "    class_probabilities: dict  # All class probabilities\n",
    "    model_version: str\n",
    "    latency_ms: float\n",
    "\n",
    "# Create FastAPI app\n",
    "app = FastAPI(\n",
    "    title=\"ADAS Model API\",\n",
    "    description=\"CNN model for detecting ADAS objects\",\n",
    "    version=\"1.0.0\"\n",
    ")\n",
    "\n",
    "print(\"âœ… FastAPI application created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b72199e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… /predict endpoint defined\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "async def predict(file: UploadFile = File(...)):\n",
    "    \"\"\"\n",
    "    Predict class of uploaded image.\n",
    "    \n",
    "    Args:\n",
    "        file: Image file (JPEG, PNG)\n",
    "    \n",
    "    Returns:\n",
    "        PredictionResponse with prediction, confidence, and model version\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Validate file type\n",
    "        allowed_extensions = {'.jpg', '.jpeg', '.png', '.gif'}\n",
    "        file_ext = Path(file.filename).suffix.lower()\n",
    "        \n",
    "        if file_ext not in allowed_extensions:\n",
    "            raise HTTPException(\n",
    "                status_code=400,\n",
    "                detail=f\"Invalid file type: {file_ext}. Allowed: {allowed_extensions}\"\n",
    "            )\n",
    "        \n",
    "        # Step 2: Read and validate image\n",
    "        contents = await file.read()\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(io.BytesIO(contents)).convert('RGB')\n",
    "        except Exception as e:\n",
    "            raise HTTPException(\n",
    "                status_code=400,\n",
    "                detail=f\"Could not open image: {str(e)}\"\n",
    "            )\n",
    "        \n",
    "        # Step 3: Validate image dimensions\n",
    "        if image.size[0] < 32 or image.size[1] < 32:\n",
    "            raise HTTPException(\n",
    "                status_code=400,\n",
    "                detail=f\"Image too small: {image.size}. Minimum: 32x32\"\n",
    "            )\n",
    "        \n",
    "        # Step 4: Transform and batch\n",
    "        image_tensor = transform(image).unsqueeze(0).to(device)  # Add batch dimension\n",
    "        \n",
    "        # Step 5: Model inference\n",
    "        with torch.no_grad():\n",
    "            outputs = model(image_tensor)\n",
    "            probabilities = torch.softmax(outputs, dim=1)\n",
    "            confidence, predicted_idx = torch.max(probabilities, 1)\n",
    "        \n",
    "        # Step 6: Format response\n",
    "        predicted_class = class_names[predicted_idx.item()]\n",
    "        confidence_value = confidence.item()\n",
    "        \n",
    "        # Get all class probabilities\n",
    "        class_probs = {}\n",
    "        for idx, class_name in enumerate(class_names):\n",
    "            class_probs[class_name] = float(probabilities[0, idx].item())\n",
    "        \n",
    "        # Calculate latency\n",
    "        latency = (time.time() - start_time) * 1000  # Convert to ms\n",
    "        \n",
    "        return PredictionResponse(\n",
    "            prediction=predicted_class,\n",
    "            confidence=round(confidence_value, 4),\n",
    "            class_probabilities=class_probs,\n",
    "            model_version=\"v1.0\",\n",
    "            latency_ms=round(latency, 2)\n",
    "        )\n",
    "    \n",
    "    except HTTPException:\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        raise HTTPException(\n",
    "            status_code=500,\n",
    "            detail=f\"Internal server error: {str(e)}\"\n",
    "        )\n",
    "\n",
    "print(\"âœ… /predict endpoint defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f812abe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Health check and info endpoints defined\n"
     ]
    }
   ],
   "source": [
    "# Health check endpoint\n",
    "@app.get(\"/health\")\n",
    "async def health_check():\n",
    "    \"\"\"\n",
    "    Check if API is alive and model is loaded.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"status\": \"healthy\",\n",
    "        \"model_version\": \"v1.0\",\n",
    "        \"classes\": class_names,\n",
    "        \"device\": str(device)\n",
    "    }\n",
    "\n",
    "# Model info endpoint\n",
    "@app.get(\"/info\")\n",
    "async def model_info():\n",
    "    \"\"\"\n",
    "    Get model information.\n",
    "    \"\"\"\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    \n",
    "    return {\n",
    "        \"model_name\": \"ResNet-18 ADAS Detector\",\n",
    "        \"version\": \"1.0\",\n",
    "        \"num_classes\": num_classes,\n",
    "        \"classes\": class_names,\n",
    "        \"input_shape\": \"128x128x3\",\n",
    "        \"total_parameters\": total_params,\n",
    "        \"device\": str(device)\n",
    "    }\n",
    "\n",
    "print(\"âœ… Health check and info endpoints defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49dadf3",
   "metadata": {},
   "source": [
    "## Step 3: Run API Server\n",
    "\n",
    "âš ï¸ **IMPORTANT**: The code below starts a server. You might want to run it in a separate terminal instead of in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "718b3666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Test client created (FastAPI TestClient)\n"
     ]
    }
   ],
   "source": [
    "# Start server (runs indefinitely until stopped)\n",
    "# Note: In Jupyter, you typically run this in a separate terminal:\n",
    "# uvicorn <script_name>:app --reload --port 8000\n",
    "\n",
    "# For notebook demo, we'll create a test client instead\n",
    "from fastapi.testclient import TestClient\n",
    "\n",
    "client = TestClient(app)\n",
    "print(\"âœ… Test client created (FastAPI TestClient)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dafa5c",
   "metadata": {},
   "source": [
    "## Step 4: Test API Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bf75a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TEST 1: Health Check Endpoint\n",
      "======================================================================\n",
      "Status Code: 200\n",
      "Response: {\n",
      "  \"status\": \"healthy\",\n",
      "  \"model_version\": \"v1.0\",\n",
      "  \"classes\": [\n",
      "    \"animal\",\n",
      "    \"name_board\",\n",
      "    \"other_vehicle\",\n",
      "    \"pedestrian\",\n",
      "    \"pothole\",\n",
      "    \"road_sign\",\n",
      "    \"speed_breaker\"\n",
      "  ],\n",
      "  \"device\": \"cpu\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Health Check\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEST 1: Health Check Endpoint\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "response = client.get(\"/health\")\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "print(f\"Response: {json.dumps(response.json(), indent=2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda47df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Model Info\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEST 2: Model Info Endpoint\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "response = client.get(\"/info\")\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "info = response.json()\n",
    "for key, value in info.items():\n",
    "    if key != 'classes':\n",
    "        print(f\"{key}: {value}\")\n",
    "    else:\n",
    "        print(f\"{key}: {', '.join(value)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0038af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Prediction with Valid Image\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEST 3: Prediction with Synthetic Image\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create a dummy image\n",
    "dummy_image = Image.new('RGB', (100, 100), color='red')\n",
    "img_bytes = io.BytesIO()\n",
    "dummy_image.save(img_bytes, format='PNG')\n",
    "img_bytes.seek(0)\n",
    "\n",
    "response = client.post(\n",
    "    \"/predict\",\n",
    "    files={\"file\": (\"test_image.png\", img_bytes, \"image/png\")}\n",
    ")\n",
    "\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    print(f\"Prediction: {result['prediction']}\")\n",
    "    print(f\"Confidence: {result['confidence']:.4f}\")\n",
    "    print(f\"Latency: {result['latency_ms']:.2f} ms\")\n",
    "    print(f\"Model Version: {result['model_version']}\")\n",
    "else:\n",
    "    print(f\"Error: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bec6262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 4: Invalid File Type (should fail)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEST 4: Invalid File Type (Edge Case)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Try to upload a text file\n",
    "response = client.post(\n",
    "    \"/predict\",\n",
    "    files={\"file\": (\"test.txt\", io.BytesIO(b\"not an image\"), \"text/plain\")}\n",
    ")\n",
    "\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "print(f\"Response: {response.json()}\")\n",
    "print(\"âœ… API correctly rejected invalid file type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d658ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 5: Corrupt/Invalid Image (should fail)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEST 5: Corrupt Image (Edge Case)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Send corrupted image data\n",
    "response = client.post(\n",
    "    \"/predict\",\n",
    "    files={\"file\": (\"corrupt.png\", io.BytesIO(b\"\\x89PNG invalid data\"), \"image/png\")}\n",
    ")\n",
    "\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "print(f\"Response: {response.json()}\")\n",
    "print(\"âœ… API correctly rejected corrupted image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a76153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 6: Image Too Small (should fail)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEST 6: Image Too Small (Edge Case)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create a very small image\n",
    "tiny_image = Image.new('RGB', (16, 16), color='blue')\n",
    "img_bytes = io.BytesIO()\n",
    "tiny_image.save(img_bytes, format='PNG')\n",
    "img_bytes.seek(0)\n",
    "\n",
    "response = client.post(\n",
    "    \"/predict\",\n",
    "    files={\"file\": (\"tiny.png\", img_bytes, \"image/png\")}\n",
    ")\n",
    "\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "print(f\"Response: {response.json()}\")\n",
    "print(\"âœ… API correctly rejected too-small image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28249e3",
   "metadata": {},
   "source": [
    "## Step 5: API Testing Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97d77b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸŽ¯ API TESTING SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "test_results = {\n",
    "    \"âœ… Health Check\": \"API is responsive\",\n",
    "    \"âœ… Model Info\": \"Metadata correctly returned\",\n",
    "    \"âœ… Valid Image\": \"Prediction successful with latency\",\n",
    "    \"âœ… File Type Validation\": \"Rejected invalid file formats\",\n",
    "    \"âœ… Image Corruption Check\": \"Rejected corrupt images\",\n",
    "    \"âœ… Size Validation\": \"Enforced minimum image dimensions\"\n",
    "}\n",
    "\n",
    "for test, result in test_results.items():\n",
    "    print(f\"{test}: {result}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸš€ KEY TAKEAWAYS:\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "1. APIs transform models into enterprise-ready services\n",
    "2. INPUT VALIDATION is crucial - never trust user input\n",
    "3. ERROR HANDLING should be graceful with meaningful messages\n",
    "4. Endpoints like /health and /info are standard practice\n",
    "5. Latency tracking helps identify performance issues\n",
    "6. Model versioning allows A/B testing and rollbacks\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1584121e",
   "metadata": {},
   "source": [
    "## Running the API Locally\n",
    "\n",
    "To run this API with FastAPI, create a file named `api.py` with the model and endpoints, then run:\n",
    "\n",
    "```bash\n",
    "pip install fastapi uvicorn python-multipart\n",
    "uvicorn api:app --reload --port 8000\n",
    "```\n",
    "\n",
    "Then test with:\n",
    "```python\n",
    "import requests\n",
    "files = {'file': open('image.jpg', 'rb')}\n",
    "response = requests.post('http://localhost:8000/predict', files=files)\n",
    "print(response.json())\n",
    "```\n",
    "\n",
    "Or use **Postman**: POST to `http://localhost:8000/predict` with form-data file upload."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_cn_new",
   "language": "python",
   "name": "venv_cn_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
